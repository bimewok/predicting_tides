{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tides.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPRWxZRINGzOxiJzhzoT0jJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bimewok/predicting_tides/blob/main/tides_3_9_21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_OzsB6tyFgN",
        "outputId": "3c0bf058-9d43-4e87-dbfa-990c46eee395"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "import pandas as pd\r\n",
        "import requests, io\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/bimewok/predicting_tides/main/data/tides.csv')\r\n",
        "\r\n",
        "data = np.array(df['height'])\r\n",
        "\r\n",
        "\r\n",
        "y = [] # cut 8\r\n",
        "x = [] # cut 3\r\n",
        "\r\n",
        "past = 14*24\r\n",
        "future = 24\r\n",
        "train_size = 0.6\r\n",
        "\r\n",
        "for i in range(len(data)):\r\n",
        "    x.append(data[i:i+past])\r\n",
        "    y.append(data[i+1:i+future+1])\r\n",
        "\r\n",
        "x = np.array(x[:-(past+future-1)])\r\n",
        "y = np.array(y[:-(past+future-1)])\r\n",
        "\r\n",
        "x = x.reshape((len(x), 1, past))\r\n",
        "y = y.reshape((len(y), 1, future))\r\n",
        "\r\n",
        "maxes = np.argmax(x)\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "import pandas as pd\r\n",
        "import requests, io\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/bimewok/predicting_tides/main/data/tides.csv')\r\n",
        "\r\n",
        "data = np.array(df['height'])\r\n",
        "\r\n",
        "\r\n",
        "y = [] # cut 8\r\n",
        "x = [] # cut 3\r\n",
        "\r\n",
        "past = 14*24\r\n",
        "future = 24\r\n",
        "train_size = 0.6\r\n",
        "\r\n",
        "for i in range(len(data)):\r\n",
        "    x.append(data[i:i+past])\r\n",
        "    y.append(data[i+1:i+future+1])\r\n",
        "\r\n",
        "x = np.array(x[:-(past+future-1)])\r\n",
        "y = np.array(y[:-(past+future-1)])\r\n",
        "\r\n",
        "x = x.reshape((len(x), 1, past))\r\n",
        "y = y.reshape((len(y), 1, future))\r\n",
        "\r\n",
        "maxes = np.mean(x)\r\n",
        "\r\n",
        "x = x / maxes\r\n",
        "y = y / maxes\r\n",
        "\r\n",
        "arr = np.arange(len(x))\r\n",
        "np.random.shuffle(arr)\r\n",
        "\r\n",
        "train_end = int(train_size*len(x))\r\n",
        "val_end = train_end + int(((1 - train_size) / 2)*len(x))\r\n",
        "\r\n",
        "x_train = x[arr[:train_end]]\r\n",
        "x_val = x[arr[train_end:val_end]]\r\n",
        "x_test = x[arr[val_end:]]\r\n",
        "\r\n",
        "y_train = y[arr[:train_end]]\r\n",
        "y_val = y[arr[train_end:val_end]]\r\n",
        "y_test = y[arr[val_end:]]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "np.random.seed(42)\r\n",
        "tf.random.set_seed(42)\r\n",
        "\r\n",
        "es = tf.keras.callbacks.EarlyStopping(\r\n",
        "    monitor=\"val_loss\",\r\n",
        "    min_delta=0,\r\n",
        "    patience=3,\r\n",
        "    verbose=0,\r\n",
        "    mode=\"auto\",\r\n",
        "    baseline=None,\r\n",
        "    restore_best_weights=False,\r\n",
        ")\r\n",
        "\r\n",
        "model = keras.models.Sequential(name='LSTM_1')\r\n",
        "\r\n",
        "model.add(keras.layers.LSTM(64, return_sequences=True, input_shape=[None, past]))\r\n",
        "model.add(keras.layers.Dense(80))\r\n",
        "model.add(keras.layers.LSTM(64, return_sequences=True))\r\n",
        "   \r\n",
        "model.add(keras.layers.TimeDistributed(keras.layers.Dense(future)))\r\n",
        "\r\n",
        "\r\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\", metrics='mean_absolute_percentage_error')\r\n",
        "history = model.fit(x_train, y_train, epochs=1000,\r\n",
        "                    validation_data=(x_val, y_val), batch_size=16, callbacks=es)\r\n",
        "pred = model.predict(x_test)\r\n",
        "\r\n",
        "print(pred.shape, pred)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "36103/36103 [==============================] - 194s 5ms/step - loss: 0.4764 - mean_absolute_percentage_error: 433.3145 - val_loss: 0.0565 - val_mean_absolute_percentage_error: 116.2944\n",
            "Epoch 2/1000\n",
            "36103/36103 [==============================] - 191s 5ms/step - loss: 0.0809 - mean_absolute_percentage_error: 124.6012 - val_loss: 0.0422 - val_mean_absolute_percentage_error: 140.1755\n",
            "Epoch 3/1000\n",
            "36103/36103 [==============================] - 188s 5ms/step - loss: 0.0520 - mean_absolute_percentage_error: 87.0921 - val_loss: 0.0399 - val_mean_absolute_percentage_error: 168.4697\n",
            "Epoch 4/1000\n",
            "36103/36103 [==============================] - 190s 5ms/step - loss: 0.0388 - mean_absolute_percentage_error: 106.3229 - val_loss: 0.0382 - val_mean_absolute_percentage_error: 199.2736\n",
            "Epoch 5/1000\n",
            "36103/36103 [==============================] - 189s 5ms/step - loss: 0.0372 - mean_absolute_percentage_error: 69.0140 - val_loss: 0.0351 - val_mean_absolute_percentage_error: 86.9913\n",
            "Epoch 6/1000\n",
            "11591/36103 [========>.....................] - ETA: 1:48 - loss: 0.0441 - mean_absolute_percentage_error: 144.8382"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}